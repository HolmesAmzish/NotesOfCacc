# 操作系统 课程设计

## 准备工作

### 安装系统环境

**安装系统**，这里选择 Ubuntu Server 22.04 LTS，对于 2025 年来说这个版本刚好，后期自行选择。记得下载 OpenSSH 服务器。

![image-20250616171433756](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616171433756.png)

首先更新一下软件源，一般源比较慢，更新成阿里云的

```bash
cacc@limbo-vi:/etc/apt$ sudo mv sources.list sources.list.bak
cacc@limbo-vi:/etc/apt$ sudo vim sources.list
```

写入

```bash
deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse

deb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse
```

更新软件源

```bash
sudo apt update
```



**安装 zsh（哈哈）**，新安装的机子别的可以不装但是要装一下zsh。

```bash
sudo apt install zsh
chsh -s $(which zsh)

sh -c "$(curl -fsSL https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh)"
vim ~/.zshrc
```

![image-20250616185059936](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616185059936.png)

### 编译内核

**下载 Linux 内核源码**

![image-20250616171858150](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616171858150.png)

```bash
wget https://www.kernel.org/pub/linux/kernel/v5.x/linux-5.15.185.tar.xz
```

![image-20250616185158212](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616185158212.png)

解压

```bash
tar -xvf linux-5.15.185.tar.xz
```

将源代码复制到 src 文件夹

```bash
sudo cp -r linux-5.15.185 /usr/src
```

![image-20250616185454116](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616185454116.png)

安装依赖工具

```bash
sudo apt update
sudo apt install build-essential libncurses-dev bison flex libssl-dev libelf-dev bc
```

内核源码提供了多种不同选择，需要进行个性化配置，最后会生成不同的发行版。这里方便编译直接将当前内核配置复制到那边。

```bash
sudo cp /boot/config-$(uname -r) .config
sudo make olddefconfig
```

编译内核

```bash
sudo make -j$(nproc)
```

![image-20250616185856074](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250616185856074.png)

这里需要漫长的等待。编译完成后检查一下是否编译成功

```bash
ls -l arch/x86/boot/bzImage
```

然后安装编译好的新内核

```bash
sudo make modules_install
# 安装新系统模块
sudo make install
# 安装新内核
```

![image-20250617101531311](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250617101531311.png)

可以看到这两个安装指令在 `/lib/modules` 和 `/boot` 中安装了新的系统文件

更新 grub，grub 是一个开机引导程序，用来引导用户开机时启动什么系统，进阶启动这个系统的什么内核，多系统启动场景常用，典型例子就是可以用来选择开机启动 Ubuntu 还是 Windows。

```bash
update-grub
```

![image-20250617101645506](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250617101645506.png)

```
reboot
```

重新登录，一般默认进入新的系统内核，也可以通过再开机时的 grub 里选择 adanced options 去手动选择启动系统的内核。登录后检查发现系统内核已经更新。

![image-20250617120350321](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250617120350321.png)



## 驱动

### 前提知识

这里首先讲几个概念，Linux 操作系统使用了一种全新的内核模块机制，**动态客家再内核模块（loadable kernel module, LKM）**。用户可以根据需求，再不需要对内核重新编译的情况下，让模块能动态地装入内核或从内核移除。

内核模块必须至少有两个函数，一个是 `init_module()` 另一个是 `cleanup_module()` ，分别在 `insmod` 和 `rmmod` 时调用。

以下是一个事例：

```c
#define MODULE
#include <linux/module.h>

int init_module(void) {
    printk("<1>Hello, World!\n");
    return 0;
}

void cleanup_module(void) {
    printk("<1>Goodbye, World!\n");
}
MODULE_LICENSE("GPL");
MODULE_AUTHOR("Amzish");
```

```makefile
obj-m+=helloworld.o
all:
	make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) modules
clean:
	make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) clean
```

![image-20250617155032545](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250617155032545.png)

这里提一下，`dmesg`（**Display Message** 或 **Driver Message**）是 Linux 系统中用于**查看内核环形缓冲区（kernel ring buffer）日志**的命令。它记录了内核启动过程、硬件检测、设备驱动初始化、系统错误等关键信息，是系统调试和故障排查的重要工具。主要显示包括硬件事件、设备驱动状态、系统错误等。

当然，也可以通过 `lsmod` 命令来查看当前装载的模块。

### ramdisk

ramdisk 驱动的目的是将计算机内存中一部分作为存储块设备，这个块设备的读写速度由于在内存，会非常快。

以下是根据 ramdisk 所更改的代码，将ramdisk创建设备数量改为 1并将容量改为 256MB，同时将设备名称改成 myram 予以区分

```c
// SPDX-License-Identifier: GPL-2.0-only
/*
 * Ram backed block device driver.
 *
 * Copyright (C) 2007 Nick Piggin
 * Copyright (C) 2007 Novell Inc.
 *
 * Parts derived from drivers/block/rd.c, and drivers/block/loop.c, copyright
 * of their respective owners.
 */

#include <linux/init.h>
#include <linux/initrd.h>
#include <linux/module.h>
#include <linux/moduleparam.h>
#include <linux/major.h>
#include <linux/blkdev.h>
#include <linux/bio.h>
#include <linux/highmem.h>
#include <linux/mutex.h>
#include <linux/pagemap.h>
#include <linux/radix-tree.h>
#include <linux/fs.h>
#include <linux/slab.h>
#include <linux/backing-dev.h>
#include <linux/debugfs.h>

#include <linux/uaccess.h>

/*
 * Each block ramdisk device has a radix_tree brd_pages of pages that stores
 * the pages containing the block device's contents. A brd page's ->index is
 * its offset in PAGE_SIZE units. This is similar to, but in no way connected
 * with, the kernel's pagecache or buffer cache (which sit above our block
 * device).
 */
struct brd_device {
    int			brd_number;
    struct gendisk		*brd_disk;
    struct list_head	brd_list;

    /*
     * Backing store of pages and lock to protect it. This is the contents
     * of the block device.
     */
    spinlock_t		brd_lock;
    struct radix_tree_root	brd_pages;
    u64			brd_nr_pages;
};

/*
 * Look up and return a brd's page for a given sector.
 */
static struct page *brd_lookup_page(struct brd_device *brd, sector_t sector)
{
    pgoff_t idx;
    struct page *page;

    /*
     * The page lifetime is protected by the fact that we have opened the
     * device node -- brd pages will never be deleted under us, so we
     * don't need any further locking or refcounting.
     *
     * This is strictly true for the radix-tree nodes as well (ie. we
     * don't actually need the rcu_read_lock()), however that is not a
     * documented feature of the radix-tree API so it is better to be
     * safe here (we don't have total exclusion from radix tree updates
     * here, only deletes).
     */
    rcu_read_lock();
    idx = sector >> PAGE_SECTORS_SHIFT; /* sector to page index */
    page = radix_tree_lookup(&brd->brd_pages, idx);
    rcu_read_unlock();

    BUG_ON(page && page->index != idx);

    return page;
}

/*
 * Insert a new page for a given sector, if one does not already exist.
 */
static int brd_insert_page(struct brd_device *brd, sector_t sector)
{
    pgoff_t idx;
    struct page *page;
    gfp_t gfp_flags;

    page = brd_lookup_page(brd, sector);
    if (page)
        return 0;

    /*
     * Must use NOIO because we don't want to recurse back into the
     * block or filesystem layers from page reclaim.
     */
    gfp_flags = GFP_NOIO | __GFP_ZERO | __GFP_HIGHMEM;
    page = alloc_page(gfp_flags);
    if (!page)
        return -ENOMEM;

    if (radix_tree_preload(GFP_NOIO)) {
        __free_page(page);
        return -ENOMEM;
    }

    spin_lock(&brd->brd_lock);
    idx = sector >> PAGE_SECTORS_SHIFT;
    page->index = idx;
    if (radix_tree_insert(&brd->brd_pages, idx, page)) {
        __free_page(page);
        page = radix_tree_lookup(&brd->brd_pages, idx);
        BUG_ON(!page);
        BUG_ON(page->index != idx);
    } else {
        brd->brd_nr_pages++;
    }
    spin_unlock(&brd->brd_lock);

    radix_tree_preload_end();
    return 0;
}

/*
 * Free all backing store pages and radix tree. This must only be called when
 * there are no other users of the device.
 */
#define FREE_BATCH 16
static void brd_free_pages(struct brd_device *brd)
{
    unsigned long pos = 0;
    struct page *pages[FREE_BATCH];
    int nr_pages;

    do {
        int i;

        nr_pages = radix_tree_gang_lookup(&brd->brd_pages,
                (void **)pages, pos, FREE_BATCH);

        for (i = 0; i < nr_pages; i++) {
            void *ret;

            BUG_ON(pages[i]->index < pos);
            pos = pages[i]->index;
            ret = radix_tree_delete(&brd->brd_pages, pos);
            BUG_ON(!ret || ret != pages[i]);
            __free_page(pages[i]);
        }

        pos++;

        /*
         * It takes 3.4 seconds to remove 80GiB ramdisk.
         * So, we need cond_resched to avoid stalling the CPU.
         */
        cond_resched();

        /*
         * This assumes radix_tree_gang_lookup always returns as
         * many pages as possible. If the radix-tree code changes,
         * so will this have to.
         */
    } while (nr_pages == FREE_BATCH);
}

/*
 * copy_to_brd_setup must be called before copy_to_brd. It may sleep.
 */
static int copy_to_brd_setup(struct brd_device *brd, sector_t sector, size_t n)
{
    unsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;
    size_t copy;
    int ret;

    copy = min_t(size_t, n, PAGE_SIZE - offset);
    ret = brd_insert_page(brd, sector);
    if (ret)
        return ret;
    if (copy < n) {
        sector += copy >> SECTOR_SHIFT;
        ret = brd_insert_page(brd, sector);
    }
    return ret;
}

/*
 * Copy n bytes from src to the brd starting at sector. Does not sleep.
 */
static void copy_to_brd(struct brd_device *brd, const void *src,
            sector_t sector, size_t n)
{
    struct page *page;
    void *dst;
    unsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;
    size_t copy;

    copy = min_t(size_t, n, PAGE_SIZE - offset);
    page = brd_lookup_page(brd, sector);
    BUG_ON(!page);

    dst = kmap_atomic(page);
    memcpy(dst + offset, src, copy);
    kunmap_atomic(dst);

    if (copy < n) {
        src += copy;
        sector += copy >> SECTOR_SHIFT;
        copy = n - copy;
        page = brd_lookup_page(brd, sector);
        BUG_ON(!page);

        dst = kmap_atomic(page);
        memcpy(dst, src, copy);
        kunmap_atomic(dst);
    }
}

/*
 * Copy n bytes to dst from the brd starting at sector. Does not sleep.
 */
static void copy_from_brd(void *dst, struct brd_device *brd,
            sector_t sector, size_t n)
{
    struct page *page;
    void *src;
    unsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;
    size_t copy;

    copy = min_t(size_t, n, PAGE_SIZE - offset);
    page = brd_lookup_page(brd, sector);
    if (page) {
        src = kmap_atomic(page);
        memcpy(dst, src + offset, copy);
        kunmap_atomic(src);
    } else
        memset(dst, 0, copy);

    if (copy < n) {
        dst += copy;
        sector += copy >> SECTOR_SHIFT;
        copy = n - copy;
        page = brd_lookup_page(brd, sector);
        if (page) {
            src = kmap_atomic(page);
            memcpy(dst, src, copy);
            kunmap_atomic(src);
        } else
            memset(dst, 0, copy);
    }
}

/*
 * Process a single bvec of a bio.
 */
static int brd_do_bvec(struct brd_device *brd, struct page *page,
            unsigned int len, unsigned int off, unsigned int op,
            sector_t sector)
{
    void *mem;
    int err = 0;

    if (op_is_write(op)) {
        err = copy_to_brd_setup(brd, sector, len);
        if (err)
            goto out;
    }

    mem = kmap_atomic(page);
    if (!op_is_write(op)) {
        copy_from_brd(mem + off, brd, sector, len);
        flush_dcache_page(page);
    } else {
        flush_dcache_page(page);
        copy_to_brd(brd, mem + off, sector, len);
    }
    kunmap_atomic(mem);

out:
    return err;
}

static blk_qc_t brd_submit_bio(struct bio *bio)
{
    struct brd_device *brd = bio->bi_bdev->bd_disk->private_data;
    sector_t sector = bio->bi_iter.bi_sector;
    struct bio_vec bvec;
    struct bvec_iter iter;

    bio_for_each_segment(bvec, bio, iter) {
        unsigned int len = bvec.bv_len;
        int err;

        /* Don't support un-aligned buffer */
        WARN_ON_ONCE((bvec.bv_offset & (SECTOR_SIZE - 1)) ||
                (len & (SECTOR_SIZE - 1)));

        err = brd_do_bvec(brd, bvec.bv_page, len, bvec.bv_offset,
                  bio_op(bio), sector);
        if (err)
            goto io_error;
        sector += len >> SECTOR_SHIFT;
    }

    bio_endio(bio);
    return BLK_QC_T_NONE;
io_error:
    bio_io_error(bio);
    return BLK_QC_T_NONE;
}

static int brd_rw_page(struct block_device *bdev, sector_t sector,
               struct page *page, unsigned int op)
{
    struct brd_device *brd = bdev->bd_disk->private_data;
    int err;

    if (PageTransHuge(page))
        return -ENOTSUPP;
    err = brd_do_bvec(brd, page, PAGE_SIZE, 0, op, sector);
    page_endio(page, op_is_write(op), err);
    return err;
}

static const struct block_device_operations brd_fops = {
    .owner =		THIS_MODULE,
    .submit_bio =		brd_submit_bio,
    .rw_page =		brd_rw_page,
};

/*
 * And now the modules code and kernel interface.
 */
static int rd_nr = 1;
module_param(rd_nr, int, 0444);
MODULE_PARM_DESC(rd_nr, "Maximum number of brd devices");

unsigned long rd_size = 262144;    // 256 MiB
module_param(rd_size, ulong, 0444);
MODULE_PARM_DESC(rd_size, "Size of each RAM disk in kbytes.");

static int max_part = 1;
module_param(max_part, int, 0444);
MODULE_PARM_DESC(max_part, "Num Minors to reserve between devices");

MODULE_LICENSE("GPL");
MODULE_ALIAS_BLOCKDEV_MAJOR(RAMDISK_MAJOR);
MODULE_ALIAS("myram");

#ifndef MODULE
/* Legacy boot options - nonmodular */
static int __init ramdisk_size(char *str)
{
    rd_size = simple_strtol(str, NULL, 0);
    return 1;
}
__setup("ramdisk_size=", ramdisk_size);
#endif

/*
 * The device scheme is derived from loop.c. Keep them in synch where possible
 * (should share code eventually).
 */
static LIST_HEAD(brd_devices);
static DEFINE_MUTEX(brd_devices_mutex);
static struct dentry *brd_debugfs_dir;

static struct brd_device *brd_find_or_alloc_device(int i)
{
    struct brd_device *brd;

    mutex_lock(&brd_devices_mutex);
    list_for_each_entry(brd, &brd_devices, brd_list) {
        if (brd->brd_number == i) {
            mutex_unlock(&brd_devices_mutex);
            return ERR_PTR(-EEXIST);
        }
    }

    brd = kzalloc(sizeof(*brd), GFP_KERNEL);
    if (!brd) {
        mutex_unlock(&brd_devices_mutex);
        return ERR_PTR(-ENOMEM);
    }
    brd->brd_number	= i;
    list_add_tail(&brd->brd_list, &brd_devices);
    mutex_unlock(&brd_devices_mutex);
    return brd;
}

static void brd_free_device(struct brd_device *brd)
{
    mutex_lock(&brd_devices_mutex);
    list_del(&brd->brd_list);
    mutex_unlock(&brd_devices_mutex);
    kfree(brd);
}

static int brd_alloc(int i)
{
    struct brd_device *brd;
    struct gendisk *disk;
    char buf[DISK_NAME_LEN];
    int err = -ENOMEM;

    brd = brd_find_or_alloc_device(i);
    if (IS_ERR(brd))
        return PTR_ERR(brd);

    spin_lock_init(&brd->brd_lock);
    INIT_RADIX_TREE(&brd->brd_pages, GFP_ATOMIC);

    snprintf(buf, DISK_NAME_LEN, "myram%d", i);
    if (!IS_ERR_OR_NULL(brd_debugfs_dir))
        debugfs_create_u64(buf, 0444, brd_debugfs_dir,
                &brd->brd_nr_pages);

    disk = brd->brd_disk = blk_alloc_disk(NUMA_NO_NODE);
    if (!disk)
        goto out_free_dev;

    disk->major		= RAMDISK_MAJOR;
    disk->first_minor	= i * max_part;
    disk->minors		= max_part;
    disk->fops		= &brd_fops;
    disk->private_data	= brd;
    disk->flags		= GENHD_FL_EXT_DEVT;
    strlcpy(disk->disk_name, buf, DISK_NAME_LEN);
    set_capacity(disk, rd_size * 2);
    
    /*
     * This is so fdisk will align partitions on 4k, because of
     * direct_access API needing 4k alignment, returning a PFN
     * (This is only a problem on very small devices <= 4M,
     *  otherwise fdisk will align on 1M. Regardless this call
     *  is harmless)
     */
    blk_queue_physical_block_size(disk->queue, PAGE_SIZE);

    /* Tell the block layer that this is not a rotational device */
    blk_queue_flag_set(QUEUE_FLAG_NONROT, disk->queue);
    blk_queue_flag_clear(QUEUE_FLAG_ADD_RANDOM, disk->queue);
    blk_queue_flag_set(QUEUE_FLAG_NOWAIT, disk->queue);
    err = add_disk(disk);
    if (err)
        goto out_cleanup_disk;

    return 0;

out_cleanup_disk:
    blk_cleanup_disk(disk);
out_free_dev:
    brd_free_device(brd);
    return err;
}

static void brd_probe(dev_t dev)
{
    brd_alloc(MINOR(dev) / max_part);
}

static void brd_cleanup(void)
{
    struct brd_device *brd, *next;

    debugfs_remove_recursive(brd_debugfs_dir);

    list_for_each_entry_safe(brd, next, &brd_devices, brd_list) {
        del_gendisk(brd->brd_disk);
        blk_cleanup_disk(brd->brd_disk);
        brd_free_pages(brd);
        brd_free_device(brd);
    }
}

static inline void brd_check_and_reset_par(void)
{
    if (unlikely(!max_part))
        max_part = 1;

    /*
     * make sure 'max_part' can be divided exactly by (1U << MINORBITS),
     * otherwise, it is possiable to get same dev_t when adding partitions.
     */
    if ((1U << MINORBITS) % max_part != 0)
        max_part = 1UL << fls(max_part);

    if (max_part > DISK_MAX_PARTS) {
        pr_info("brd: max_part can't be larger than %d, reset max_part = %d.\n",
            DISK_MAX_PARTS, DISK_MAX_PARTS);
        max_part = DISK_MAX_PARTS;
    }
}

static int __init brd_init(void)
{
    int err, i;

    /*
     * brd module now has a feature to instantiate underlying device
     * structure on-demand, provided that there is an access dev node.
     *
     * (1) if rd_nr is specified, create that many upfront. else
     *     it defaults to CONFIG_BLK_DEV_RAM_COUNT
     * (2) User can further extend brd devices by create dev node themselves
     *     and have kernel automatically instantiate actual device
     *     on-demand. Example:
     *		mknod /path/devnod_name b 1 X	# 1 is the rd major
     *		fdisk -l /path/devnod_name
     *	If (X / max_part) was not already created it will be created
     *	dynamically.
     */

    brd_check_and_reset_par();

    brd_debugfs_dir = debugfs_create_dir("myram_pages", NULL);

    if (__register_blkdev(RAMDISK_MAJOR, "myram", brd_probe)) {
        err = -EIO;
        goto out_free;
    }

    for (i = 0; i < rd_nr; i++)
        brd_alloc(i);

    pr_info("myram: module loaded\n");
    return 0;

out_free:
    brd_cleanup();

    pr_info("myram: module NOT loaded !!!\n");
    return err;
}

static void __exit brd_exit(void)
{

    unregister_blkdev(RAMDISK_MAJOR, "ramdisk");
    brd_cleanup();

    pr_info("myram: module unloaded\n");
}

module_init(brd_init);
module_exit(brd_exit);
```

Makefile

```makefile
obj-m += myram.o

KDIR := /lib/modules/$(shell uname -r)/build
PWD := $(shell pwd)

all:
	make -C $(KDIR) M=$(PWD) modules

clean:
	make -C $(KDIR) M=$(PWD) clean
```

编译模块，找到输出文件 .ko 然后加载驱动。

![image-20250618212234933](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250618212234933.png)

```bash
make

sudo insmod myram.ko  # 装载
lsmod  # 列出装载的模块
```

创建文件系统

```bash
cacc@limbo-vi [01:00:05 PM] [~/modules/myram] 
-> % sudo mkfs.ext4 /dev/myram0 
[sudo] password for cacc: 
mke2fs 1.46.5 (30-Dec-2021)
Creating filesystem with 65536 4k blocks and 65536 inodes
Filesystem UUID: 1d705cf4-19b5-4293-a05c-6b6b39d6d0f4
Superblock backups stored on blocks: 
	32768

Allocating group tables: done                            
Writing inode tables: done                            
Creating journal (4096 blocks): done
Writing superblocks and filesystem accounting information: done
```

这里将块设备 myram0 创建为 ext4 文件系统

挂载

```bash
sudo mount /dev/myram0 /mnt/myram
df -h
```

![image-20250618212602754](/home/cacc/Documents/NotesOfCacc/学校文件/操作系统/assets/image-20250618212602754.png)

测试文件读写

```bash
root@limbo-vi:/mnt/myram# echo "hello" >> hello.txt
root@limbo-vi:/mnt/myram# cat hello.txt 
hello
root@limbo-vi:/mnt/myram# 
```

最后取消挂载并卸载模块

```bash
cacc@limbo-vi [01:28:07 PM] [/mnt] 
-> % sudo umount -f /mnt/myram                        
cacc@limbo-vi [01:28:40 PM] [/mnt] 
-> % sudo rmmod myram                            
```



