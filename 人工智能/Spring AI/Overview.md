---
title: Spring AI
date: 2025-04-28
---



# AI Concepts

## Models

<img src="https://docs.spring.io/spring-ai/reference/_images/spring-ai-concepts-model-types.jpg" width=80%>

## Embeddings

<img src="https://docs.spring.io/spring-ai/reference/_images/spring-ai-embeddings.jpg" width=100%>

## Tokens

Tokens serve as the building blocks of how an AI model works. On input, models convert words to tokens. On output, they convert tokens back to words.

<img src="https://docs.spring.io/spring-ai/reference/_images/spring-ai-concepts-tokens.png" width=60%>

## Bringing Your Data & APIs to the AI Model

Three techniques exist for customizing the AI model to incorporate your data:

**Fine Tuning**: This traditional machine learning technique involves tailoring the model and changing its internal weighting. However, it is a challenging process for machine learning experts and extremely resource-intensive for models like GPT due to their size. Additionally, some models might not offer this option.

### Retrieval Augmented Generation

**Pormpt Stuffing**: A more practical alternative involves embedding your data within the prompt provided to the model. Given a model's token limits, techniques are required to present relevand data within the model's context window. This approach is colloquially referred to as "stuffing the prompt." The Spring AI library helps you implement solutions based on the "stuffing the prompt" technique otherwise known as **Retrieval Augmented Generation (RAG)**.

提示词填充：一种更实用的方法是将您的数据嵌入到提供给模型的提示词中。由于模型存在令牌（token）限制，需要通过技术手段在模型的上下文窗口内呈现相关数据。这种方法被通俗地称为"填充提示词"。Spring AI 库可帮助您实现基于提示词填充（**检索增强生成**，RAG）的解决方案。

<img src="https://docs.spring.io/spring-ai/reference/_images/spring-ai-prompt-stuffing.jpg" width=100%>

A technique termed Retrieval Augmented Generateion (RAG) has emerged to address the challenge of incorporating relevant data into prompts for accurate AL model responses.

The approach involves a batch processing style programming model, where the job reads unstructured data from your documents, transforms it, and then writes it into a vector database. At a high level, this is an ETL (Extract, Transform and Load) pipeline. The vector database is used in the retrieval part of RAG technique.

When a user's question is to be answered by an AI model, the question and all the "similar" document pieces are placed into the prompt that is sent to the AI model. This is the reason to use a vector database. It is very good at finding similar content.

<img src="https://docs.spring.io/spring-ai/reference/_images/spring-ai-rag.jpg">

### Tool Calling

**Tool Calling**: This technique allows registering tools (user-defined services) that connect the large language models to the APIs of external systems. Spring AI greatly simplifies code you need to write to support tool calling.

<img src="https://docs.spring.io/spring-ai/reference/_images/tools/tool-calling-01.jpg" width=70%>

# Chat Client API

The `ChatClient` offers a fluent API for communicating with an AI Model. It supports both a synchronous and streaming programming model.

The fluent API has methods for building up the constituent parts of a Prompt that is passed to the AI model as input. The `Prompt` contains the instructional text to guide the AI mode's output and behavior. From the API point of view, prompts consist of a collection of messages.

The AI model processes two main types of messages: user messages, which are direct inputs from the user, and system messages, which are generated by the system to guide the conversation.

These messages often contain placeholders that are substitued at tuntime based on user input to customize the response of the AI model to the user input.

There are also Prompt options that can be specified, such as the name of the AI Model to use and the temperature setting that controls the randomness or creativity of the generated output.

## Creating a ChatClient

The `ChatClient` is created using a `ChatClient.Builder` object. You can obtain an autoconfigured `ChatClient.Builder` instance for any ChatModel Spring Boot autoconfiguration or create one programmatically.

### Using an autoconfigured ChatClient.Builder

In the most simple use case, Spring AI provides Spring Boot autoconfiguration, creating a prototype `ChatClient.Builder` bean for you to inject into your class. Here is a simple example of retrieving a `String` response to a simple user request.

```java
@RestController
class MyController {
    private final ChatClient chatClient;
    public MyController(ChatClient.Builder chatClientBuilder) {
        this.chatClient = chatClientBUilder.build();
    }
    
    @GetMapping("/ai")
    String generation(String userInput) {
        return this.chatClient.prompt()
            .user(userInput)
            .call()
            .content();
    }
}
```

### Create a ChatClient programmatically

You can disable the `ChatClient.Builder` autoconfiguration by setting the property `spring.ai.chat.client.enabled=false`. This is useful if multiple chat models are used together. Then, create a `ChatClient.Builder` instance programmatically for every `ChatModel` you need:

```java
ChatModel myChatModel = ... // usually autowired

ChatClient.Builder builder = ChatClient.builder(this.myChatModel);

// or create a ChatClient with the default builder settings:

ChatClient chatClient = ChatClient.create(this.myChatModel);
```

## ChatClient Fluent API

The `ChatClient` fluent API allows you to create a prompt in three distinct ways using an overloaded `prompt` method to initiate the fluent API:

- `prompt()`: This method with no arguments lets you start using the fluent API, allowing you to build up user, systems, and other parts of the prompt.
- `prompt(Prompt prompt)`: This method accepts a `Prompt` argument, letting you pass in a `Prompt` instance that you have created using the Prompt's non-fluent APIs.
- `prompt(String content)`: This is a convenience method similar to the previous overload. It takes the user's text content.

## ChatClient Responses

The `ChatClient` API offers several ways to format the response from the AI Model using the fluent API.

### Returning a ChatResponse

The response from the AI model is a rich structure defined by the type `ChatResponse`. It includes metadata about how the response was generated and can also contain multiple responses, known as Generations, each with its own metadata. The metadata includes the number of tokens (each token is approximately 3/4 of a word) used to create the response. This information is important because hosted AI models charg based on the number of tokens used per request.

An example to return the `ChatResponse` object that contains the metadata is shown below by invoking `chatResponse()` after the `call()` method.

```java
ChatResponse chatResponse = chatClient.prompt()
    .user("Tell me a joke")
    .call()
    .chatResponse();
```

