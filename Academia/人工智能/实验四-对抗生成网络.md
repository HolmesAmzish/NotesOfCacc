# 实验四 对抗生成网络（GAN）与 MNIST 手写数字

## 理论基础

### 基本介绍

**对抗生成网络**（Generative Adversarial Network, GAN）是非监督式学习的一种方法，通过两个神经网络相互博弈的方式进行学习。其中生成对抗网络由一个生成网络（**生成器**，Generator）与一个判别网络（**判别器**，Discriminator）组成。生成网络从潜在空间中随机取样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。

![remotesensing-12-01149-g001-550.jpg](../../assets/7176d9355951eaecd5be54d9a62bda57d83c31d4.jpg)

### 数学解释

原始论文中 GAN 的数学定义如下：

$$
\min_G \max_D V(D, G) = 
\mathbb{E}_{x \sim p_{\text{data}}} [\log D(x)] +
\mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))]
$$

其中判别器的损失函数：

$$
\mathcal{L}_D = -\mathbb{E}_{x \sim p_{\text{data}}} [\log D(x)]
- \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))]
$$

生成器的损失函数：

$$
\mathcal{L}_G = \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))]
$$

## 实验内容

### 准备

库的导入

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torchvision.utils as vutils
import matplotlib.pyplot as plt
import os

# Use gpu
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
```

导入数据集，这里直接使用 torch 的 api 提供的数据集。下载到本地，可以指定目录

```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

dataset = datasets.MNIST(root="~/Workspace/Dataset/MNIST", train=True, download=False, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)
```

### 模型定义

生成器定义，MNIST 数据集是 28*28 的手写数字，所以可以做一个比较简单的定义即可

```python
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(100, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 784),
            nn.Tanh(),
        )

    def forward(self, x):
        output = self.model(x)
        output = output.view(x.size(0), 1, 28, 28)
        return output
```

判别器定义

```python
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(784, 1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        x = x.view(x.size(0), 784)
        output = self.model(x)
        return output
```

### 模型编译

参数设置

```python
batch_size = 128
z_dim = 100
lr = 2e-4
beta1 = 0.5
num_epochs = 100
sample_dir = "./samples"
os.makedirs(sample_dir, exist_ok=True)
```

初始化网络

```python
G = Generator().to(device)
D = Discriminator().to(device)

def weights_init(m):
    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    if isinstance(m, nn.BatchNorm2d):
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

G.apply(weights_init)
D.apply(weights_init)
```

损失函数与优化器

```python
criterion = nn.BCELoss()
optimizerD = optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))
```

### 训练与结果

初始化训练记录

```python
losses_D = []
losses_G = []
fixed_noise = torch.randn(64, 100, device=device)  # shape (64,100)
```

训练循环

```python
for epoch in range(1, num_epochs+1):
    for i, (real_images, _) in enumerate(dataloader):
        real_images = real_images.to(device)
        b_size = real_images.size(0)

        # -------- 更新 D --------
        D.zero_grad()
        label_real = torch.ones(b_size, 1, device=device)
        label_fake = torch.zeros(b_size, 1, device=device)

        output_real = D(real_images)
        lossD_real = criterion(output_real, label_real)

        noise = torch.randn(b_size, 100, device=device)  # shape (b_size,100)
        fake_images = G(noise)

        output_fake = D(fake_images.detach())
        lossD_fake = criterion(output_fake, label_fake)

        lossD = lossD_real + lossD_fake
        lossD.backward()
        optimizerD.step()

        # -------- 更新 G --------
        G.zero_grad()
        output = D(fake_images)
        lossG = criterion(output, label_real)
        lossG.backward()
        optimizerG.step()

    # 记录每个 epoch 的损失
    losses_D.append(lossD.item())
    losses_G.append(lossG.item())

    # 打印训练信息
    print(f"Epoch [{epoch}/{num_epochs}]  Loss_D: {lossD.item():.4f}  Loss_G: {lossG.item():.4f}")

    # 每 10 epoch 保存生成样本
    if epoch % 10 == 0:
        with torch.no_grad():
            fake_samples = G(fixed_noise).detach().cpu()
        vutils.save_image(fake_samples, f"{sample_dir}/epoch_{epoch}.png", normalize=True, nrow=8)

        # Notebook 可视化
        grid = vutils.make_grid(fake_samples, padding=2, normalize=True)
        grid = 1 - grid  # 反转颜色
        plt.figure(figsize=(6,6))
        plt.axis("off")
        plt.title(f"Generated Images at Epoch {epoch}")
        plt.imshow(grid.permute(1,2,0))
        plt.show()
```

| ![](../../assets/2025-10-20-14-37-51-image.png) | ![](../../assets/2025-10-20-14-38-07-image.png) | ![](../../assets/2025-10-20-14-38-17-image.png) | ![](../../assets/2025-10-20-14-38-26-image.png) | ![](../../assets/2025-10-20-14-38-36-image.png) |
| ----------------------------------------------- | ----------------------------------------------- | ----------------------------------------------- | ----------------------------------------------- | ----------------------------------------------- |
| ![](../../assets/2025-10-20-14-38-01-image.png) | ![](../../assets/2025-10-20-14-38-12-image.png) | ![](../../assets/2025-10-20-14-38-22-image.png) | ![](../../assets/2025-10-20-14-38-32-image.png) | ![](../../assets/2025-10-20-14-38-41-image.png) |

将记录的损失通过 `matplotlib` 打印出来，可以看到模型收敛，生成器损失降低，而判别器的损失相比最初上升。

![](../../assets/2025-10-20-14-48-30-image.png)

保存模型

```python
torch.save(G.state_dict(), "./generator.pth")
torch.save(D.state_dict(), "./discriminator.pth")
```

利用模型生成最终样本

```python
with torch.no_grad():
    fake_samples = G(fixed_noise).detach().cpu()
grid = vutils.make_grid(fake_samples, padding=2, normalize=True)
grid = 1 - grid
plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Final Generated MNIST Samples")
plt.imshow(grid.permute(1,2,0))
plt.show()
```

![](../../assets/2025-10-20-14-48-58-image.png)
