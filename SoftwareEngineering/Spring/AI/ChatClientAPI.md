---
title: ChatClient API
date: 2025-05-14
author: Holmes Amzish
---



The `ChatClient` offers a fluent API for communicating with an AI Model. It supports both a synchronous and streaming programming model.

The fluent API has methods for building up the constituent parts of a Prompt that is passed to the AI model as input. The `Prompt` contains the instructional text to guide the AI mode's output and behavior. From the API point of view, prompts consist of a collection of messages.

The AI model processes two main types of messages: user messages, which are direct inputs from the user, and system messages, which are generated by the system to guide the conversation.

These messages often contain placeholders that are substitued at tuntime based on user input to customize the response of the AI model to the user input.

There are also Prompt options that can be specified, such as the name of the AI Model to use and the temperature setting that controls the randomness or creativity of the generated output.

# Creating a ChatClient

The `ChatClient` is created using a `ChatClient.Builder` object. You can obtain an autoconfigured `ChatClient.Builder` instance for any ChatModel Spring Boot autoconfiguration or create one programmatically.

## Using an autoconfigured ChatClient.Builder

In the most simple use case, Spring AI provides Spring Boot autoconfiguration, creating a prototype `ChatClient.Builder` bean for you to inject into your class. Here is a simple example of retrieving a `String` response to a simple user request.

```java
@RestController
class MyController {
    private final ChatClient chatClient;
    public MyController(ChatClient.Builder chatClientBuilder) {
        this.chatClient = chatClientBUilder.build();
    }
    
    @GetMapping("/ai")
    String generation(String userInput) {
        return this.chatClient.prompt()
            .user(userInput)
            .call()
            .content();
    }
}
```

### Create a ChatClient programmatically

You can disable the `ChatClient.Builder` autoconfiguration by setting the property `spring.ai.chat.client.enabled=false`. This is useful if multiple chat models are used together. Then, create a `ChatClient.Builder` instance programmatically for every `ChatModel` you need:

```java
ChatModel myChatModel = ... // usually autowired

ChatClient.Builder builder = ChatClient.builder(this.myChatModel);

// or create a ChatClient with the default builder settings:

ChatClient chatClient = ChatClient.create(this.myChatModel);
```

## Working with Multiple Chat Models

By default, Spring AI autoconfigures a single `ChatClient.Builder` bean. However, you may need to work with multiple chat models in your application. Here's how to handle this scenario:

In all cases, you need to disable the `ChatClient.BUilder` autoconfiguration by setting the property `spring.ai.chat.client.enabled=false`.

This allows you to create multiple `ChatClient` instances manually.

### Multiple ChatClients with a Single Model Type

```java
// Create ChatClient instances programmatically
ChatModel myChatModel = ...
ChatClient chatClient = ChatClient.create(myChatModel);

// Or use the builder for mroe control
ChatClient.Builder builder = ChatClient.builder(myChatModel);
ChatClient customChatClient = builder
    .defaultSystemPormpt("You are a helpful assistant.")
    .build();
```

### ChatClient for Differen Model Types

When working with multiple AI models, you can define separate `ChatClient` beans for each model:

```java
@Configuration
public class ChatClientConfig {
    @Bean
    public ChatClient openAiChatClient(OpenAiChatModel chatModel) {
        return ChatClient.create(chatModel);
    }
    
    @Bean
    public ChatClient anthropicChatClient(ANthropicChatModel chatModel) {
        return ChatClient.create(chatModel);
    }
}
```

You can then inject these beans into your application components using the `@Qualifier` annotation:

```java
@Configuration
public class ChatClientExample {
    @Bean
    CommandLineRunner cli(
            @Qualifier("openAiChatClient") ChatClient openAiChatClient,
            @Qualifier("anthropicChatClient") ChatClient anthropicChatClient) {

        return args -> {
            var scanner = new Scanner(System.in);
            ChatClient chat;

            // Model selection
            System.out.println("\nSelect your AI model:");
            System.out.println("1. OpenAI");
            System.out.println("2. Anthropic");
            System.out.print("Enter your choice (1 or 2): ");

            String choice = scanner.nextLine().trim();

            if (choice.equals("1")) {
                chat = openAiChatClient;
                System.out.println("Using OpenAI model");
            } else {
                chat = anthropicChatClient;
                System.out.println("Using Anthropic model");
            }

            // Use the selected chat client
            System.out.print("\nEnter your question: ");
            String input = scanner.nextLine();
            String response = chat.prompt(input).call().content();
            System.out.println("ASSISTANT: " + response);

            scanner.close();
        };
    }
}
```



# ChatClient Fluent API

The `ChatClient` fluent API allows you to create a prompt in three distinct ways using an overloaded `prompt` method to initiate the fluent API:

- `prompt()`: This method with no arguments lets you start using the fluent API, allowing you to build up user, systems, and other parts of the prompt.
- `prompt(Prompt prompt)`: This method accepts a `Prompt` argument, letting you pass in a `Prompt` instance that you have created using the Prompt's non-fluent APIs.
- `prompt(String content)`: This is a convenience method similar to the previous overload. It takes the user's text content.

# ChatClient Responses

The `ChatClient` API offers several ways to format the response from the AI Model using the fluent API.

## Returning a ChatResponse

The response from the AI model is a rich structure defined by the type `ChatResponse`. It includes metadata about how the response was generated and can also contain multiple responses, known as Generations, each with its own metadata. The metadata includes the number of tokens (each token is approximately 3/4 of a word) used to create the response. This information is important because hosted AI models charg based on the number of tokens used per request.

An example to return the `ChatResponse` object that contains the metadata is shown below by invoking `chatResponse()` after the `call()` method.

```java
ChatResponse chatResponse = chatClient.prompt()
    .user("Tell me a joke")
    .call()
    .chatResponse();
```

## Returnning an Entity



## Streaming Responses

The `stream()` method lets you get an asynchronous response as shown below:

```java
Flux<String> output = chatClient.prompt()
    .user("Hello!")
    .stream()
    .content();
```

